[
  {
    "objectID": "working papers.html",
    "href": "working papers.html",
    "title": "Working Papers",
    "section": "",
    "text": "My current working papers and works in progress include:\n\n“Unpacking the Gendered Dimensions of Political Violence: Coparticipation and Centrality of Women in the Rwandan Genocide” with Jared F. Edgerton, Elizabeth L. Brannon, & Hollie Nyseth Nzitatira\n“Domestic Human Rights NGOs and Victim’s Support in International Human Rights Litigation”\n”"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dagmar Heintze",
    "section": "",
    "text": "I am a political science doctoral student, studying International Relations at the University of Texas at Dallas. My research topics are Conflict, Human Rights, and International Law.\n\nMy research focuses on conflict processes and political violence, specifically which factors mobilize individuals to participate in political violence and how this violence affects communities in the aftermath.\nI further focus on the prevention of torture and inhuman and degrading behavior or punishment and international mechanisms seeking to accomplish improved compliance with international human rights law.\nFurthermore, I research international human rights litigation at regional and international courts and the UN treaty bodies.\n\n\nGet in touch: dagmar.heintze@utdallas.edu | Twitter | Bluesky Social"
  },
  {
    "objectID": "Lab04_UL.html",
    "href": "Lab04_UL.html",
    "title": "EPPS 6323: Lab04 R programming (Unsupervised learning)",
    "section": "",
    "text": "Unsupervised learning is a class of machine learning algorithms to identify patterns or grouping structure in the data. Unlike supervised learning which relies on “supervised” information such as the dependent variable to guide modeling, unsupervised learning seeks to explore the structure and possible groupings of unlabeled data. This information will be useful to provide pre-processor for supervised learning.\nUnsupervised learning has no explicit dependent variable of Y for prediction. Instead, the goal is to discover interesting patterns about the measurements on \\((X_{1}), (X_{2}), . . . , (X_{p})\\) and identify any subgroups among the observations.\nGenerally, in this section, the two general methods are introduced: Principal components analysis and Clustering.\n\n\nPrincipal Components Analysis (PCA) produces a low-dimensional representation of a dataset. It finds a sequence of linear combinations of the variables that have maximal variance, and are mutually uncorrelated.\nThe first principal component of a set of features \\((X_1, X_2, . . . , X_p)\\) is the normalized linear combination of the features:  \\[  Z_1 = \\phi_{11}X_1 +\\phi_{21}X_2 +...+\\phi_{p1}X_p \\] \nthat has the largest variance. By normalized, we mean that \\(\\sum_{j=1}^p\\phi_{j1}^2 = 1\\).\nThe elements \\((\\phi_{11}, . . . , \\phi_{p1})\\) are the loadings of the first principal component; together, the loadings make up the principal component loading vector, \\(\\phi_1= (\\phi_{11} \\phi_{21} ... \\phi_{p1})^T\\)\nWe constrain the loadings so that their sum of squares is equal to one, since otherwise setting these elements to be arbitrarily large in absolute value could result in an arbitrarily large variance.\n\n\n\n\n\nThe K-means clustering method is to partition the data points into k groups such that the sum of squares from points to the assigned cluster center in each group is minimized.\n\n\n\nHierarchical clustering is an alternative approach which does not require a pre-specified or a particular choice of \\((K)\\).\nHierarchical Clustering has an advantage that it produces a tree-based representation of the observations: Dendrogram\nA dendrogram is built starting from the leaves and combining clusters up to the trunk. The result of hierarchical clustering is a tree-based representation of the objects, which is also known as dendrogram. Observations can be subdivided into groups by cutting the dendrogram at a desired similarity level."
  },
  {
    "objectID": "Lab04_UL.html#principal-component-analysis-pca",
    "href": "Lab04_UL.html#principal-component-analysis-pca",
    "title": "EPPS 6323: Lab04 R programming (Unsupervised learning)",
    "section": "",
    "text": "Principal Components Analysis (PCA) produces a low-dimensional representation of a dataset. It finds a sequence of linear combinations of the variables that have maximal variance, and are mutually uncorrelated.\nThe first principal component of a set of features \\((X_1, X_2, . . . , X_p)\\) is the normalized linear combination of the features:  \\[  Z_1 = \\phi_{11}X_1 +\\phi_{21}X_2 +...+\\phi_{p1}X_p \\] \nthat has the largest variance. By normalized, we mean that \\(\\sum_{j=1}^p\\phi_{j1}^2 = 1\\).\nThe elements \\((\\phi_{11}, . . . , \\phi_{p1})\\) are the loadings of the first principal component; together, the loadings make up the principal component loading vector, \\(\\phi_1= (\\phi_{11} \\phi_{21} ... \\phi_{p1})^T\\)\nWe constrain the loadings so that their sum of squares is equal to one, since otherwise setting these elements to be arbitrarily large in absolute value could result in an arbitrarily large variance."
  },
  {
    "objectID": "Lab04_UL.html#clustering",
    "href": "Lab04_UL.html#clustering",
    "title": "EPPS 6323: Lab04 R programming (Unsupervised learning)",
    "section": "",
    "text": "The K-means clustering method is to partition the data points into k groups such that the sum of squares from points to the assigned cluster center in each group is minimized.\n\n\n\nHierarchical clustering is an alternative approach which does not require a pre-specified or a particular choice of \\((K)\\).\nHierarchical Clustering has an advantage that it produces a tree-based representation of the observations: Dendrogram\nA dendrogram is built starting from the leaves and combining clusters up to the trunk. The result of hierarchical clustering is a tree-based representation of the objects, which is also known as dendrogram. Observations can be subdivided into groups by cutting the dendrogram at a desired similarity level."
  }
]