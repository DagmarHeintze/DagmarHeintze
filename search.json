[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dagmar Heintze",
    "section": "",
    "text": "I am a doctoral student studying International Relations. My research topics are Conflict, Human Rights, and International Law.\nMy main research interests are :\n\nMy research focuses on conflict processes and political violence, specifically which factors mobilize individuals to participate in political violence and how this violence affects communities in the aftermath.\nI further focus on the prevention of torture and inhuman and degrading behavior or punishment and international mechanisms seeking to accomplish improved compliance with international human rights law.\nFurthermore, I research international human rights litigation at regional and international courts and the UN treaty bodies.\n\nContact me dagmar.heintze@utdallas.edu\nWebsite"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "assignment1.html",
    "href": "assignment1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "A comparison of Breiman (2001) and Shmueli (2010)\nBreiman (2001) and Shmueli (2010) promote a more inclusive approach to conducting statistical modeling, moving from merely explanatory models to algorithmic/predictive modeling approaches.\n\nBreiman (2001) argues that statistical modeling up until the publication of his article has primarily focused on one method of statistical modeling of data to draw conclusions - the usage of data models. These models assume that data is derived from a stochastic model, and conclusions are drawn from the models based on this assumption. Breiman (2001) argues that the primary focus on stochastic modeling strategies can lead to inaccurate conclusions and theoretical assumptions that do not accurately describe the processes they seek to explain. Instead of focusing almost exclusively on stochastic models, Breiman (2001) promotes the usage of algorithmic models that were used more frequently in other fields outside of statistics but allow for processing large and complex data sets and more reliable conclusions when working with smaller data sets. When algorithmic models are used, the models can achieve better predictions and better explain underlying mechanisms. Breiman (2001) highlights that different approaches, such as random forests, can lead to a significantly reduced error rate compared to stochastic approaches, such as logistic regression analyses. Researchers can test their findings for accuracy when running data models and comparing the results with predictions. However, Breiman (2001) does not advocate against using data models per se but instead encourages the usage of appropriate models for the question at hand.\n\nShmueli (2010) takes up Breiman’s (2001) argument by arguing that, while explanatory modeling is commonly used, predictive modeling continues to be mostly ignored in scientific attempts to develop theory. Shmueli (2010) argues that predictive modeling approaches and predictive testing can fulfill several relevant scientific functions that cannot be easily fulfilled by explanatory modeling alone. Predictive modeling allows for the assessment of possible causal mechanisms in large data sets, the development of new measures, the uncovering of complex data patterns, an assessment of the gap between theory and practice, permits the assessment of competing theories and allows for an evaluation of the predictive power of relationships that can be statistically measured. Shmueli (2010) further expands Breiman’s (2001) argument by discussing not only the two different approaches of data vs. algorithmic modeling but also including a discussion of the data analysis process and taking four aspects (causation-association, theory-data, retrospective-prospective, and bias-variance) into account. In line with Breiman (2001), Shmueli (2010) does not discount the value of explanatory modeling per se. While Breiman (2001) argues that statistical modeling approaches should be selected according to the problem at hand, Shmueli (2010) argues that a model’s explanatory and predictive power are two distinct qualities of a well-rounded model and, therefore, predictive modeling should be included and tested together with explanatory modeling approaches. Without predictive modeling, existing theories cannot be tested regarding their relevance, and new causal mechanisms are not identified. A model’s explanatory power is not equal to its predictive power, and without a separate assessment and comparison, researchers may draw inaccurate conclusions. Furthermore, Shmueli (2010) argues that by excluding predictive modeling approaches, a gap between theory and practice continues to exist, and scientific research advances are stumped, which could both be addressed by combining both modeling approaches. Furthermore, while a model may not be bad if it does not have predictive or explanatory power but rather emphasizes the alternative quality, both explanatory and predictive modeling results should be presented in the research to allow for a well-rounded assessment of the results.\n\nIn summary, both Breiman (2001) and Shmueli (2010) argue that explanatory modeling is not the only way to approach statistical modeling, but we should also consider predictive modeling. Both authors further argue that, as a scientific community, we should know which models serve what scientific purpose and be able to differentiate them and apply them accordingly. Only then can we minimize error and reliably test our theories."
  },
  {
    "objectID": "working papers.html",
    "href": "working papers.html",
    "title": "Working Papers",
    "section": "",
    "text": "My current working papers and works in progress include:\n\n“Unpacking the Gendered Dimensions of Political Violence: Coparticipation and Centrality of Women in the Rwandan Genocide” with Jared F. Edgerton, Elizabeth L. Brannon, & Hollie Nyseth Nzitatira\n“Domestic Human Rights NGOs and Victim’s Support in International Human Rights Litigation”"
  },
  {
    "objectID": "Lab01.html",
    "href": "Lab01.html",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "x &lt;- c(1,3,2,5)\nx\n\n[1] 1 3 2 5\n\nx = c(1,6,2)\nx\n\n[1] 1 6 2\n\ny = c(1,4,3)\n\n\n\n\n\nlength(x)  # What does length() do?\n\n[1] 3\n\nlength(y)\n\n[1] 3\n\n\n\n\n\n\nx+y\n\n[1]  2 10  5\n\nls() # List objects in the environment\n\n[1] \"x\" \"y\"\n\nrm(x,y) # Remove objects\nls()\n\ncharacter(0)\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!\n\n\n\n\n\n?matrix\nx=matrix(data=c(1,2,3,4), nrow=2, ncol=2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx=matrix(c(1,2,3,4),2,2)\nmatrix(c(1,2,3,4),2,2,byrow=T) # What about byrow=F?\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx=rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny=x+rnorm(50,mean=50,sd=.1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9938792\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(3) # Try different seeds?\ny=rnorm(100)\n\n\n\n\n\nmean(y)\n\n[1] 0.01103557\n\nvar(y)\n\n[1] 0.7328675\n\nsqrt(var(y))\n\n[1] 0.8560768\n\nsd(y)\n\n[1] 0.8560768\n\n\n\n\n\n\nx=rnorm(100)\ny=rnorm(100)\nplot(x,y)\n\n\n\n\n\n\n\nplot(x,y, pch=20, col = \"firebrick\") # Scatterplot for two numeric variables by default\n\n\n\n\n\n\n\nplot(x,y, pch=20, col = \"steelblue\",xlab=\"this is the x-axis\",ylab=\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\n\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\nplot(x,y,pch=20, col=\"forestgreen\") # Try different colors?\ndev.off() # Close the file using the dev.off function\n\nquartz_off_screen \n                2 \n\nx=seq(1,10) # Same as x=c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=seq(-pi,pi,length=50)\ny=x"
  },
  {
    "objectID": "Lab01.html#create-object-using-the-assignment-operator--",
    "href": "Lab01.html#create-object-using-the-assignment-operator--",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "x &lt;- c(1,3,2,5)\nx\n\n[1] 1 3 2 5\n\nx = c(1,6,2)\nx\n\n[1] 1 6 2\n\ny = c(1,4,3)"
  },
  {
    "objectID": "Lab01.html#using-function",
    "href": "Lab01.html#using-function",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "length(x)  # What does length() do?\n\n[1] 3\n\nlength(y)\n\n[1] 3"
  },
  {
    "objectID": "Lab01.html#using---operators",
    "href": "Lab01.html#using---operators",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "x+y\n\n[1]  2 10  5\n\nls() # List objects in the environment\n\n[1] \"x\" \"y\"\n\nrm(x,y) # Remove objects\nls()\n\ncharacter(0)\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!"
  },
  {
    "objectID": "Lab01.html#matrix-operations",
    "href": "Lab01.html#matrix-operations",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "?matrix\nx=matrix(data=c(1,2,3,4), nrow=2, ncol=2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx=matrix(c(1,2,3,4),2,2)\nmatrix(c(1,2,3,4),2,2,byrow=T) # What about byrow=F?\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx=rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny=x+rnorm(50,mean=50,sd=.1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9938792\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(3) # Try different seeds?\ny=rnorm(100)"
  },
  {
    "objectID": "Lab01.html#simple-descriptive-statistics-base",
    "href": "Lab01.html#simple-descriptive-statistics-base",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "mean(y)\n\n[1] 0.01103557\n\nvar(y)\n\n[1] 0.7328675\n\nsqrt(var(y))\n\n[1] 0.8560768\n\nsd(y)\n\n[1] 0.8560768"
  },
  {
    "objectID": "Lab01.html#visualization-using-r-graphics-without-packages",
    "href": "Lab01.html#visualization-using-r-graphics-without-packages",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "x=rnorm(100)\ny=rnorm(100)\nplot(x,y)\n\n\n\n\n\n\n\nplot(x,y, pch=20, col = \"firebrick\") # Scatterplot for two numeric variables by default\n\n\n\n\n\n\n\nplot(x,y, pch=20, col = \"steelblue\",xlab=\"this is the x-axis\",ylab=\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\n\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\nplot(x,y,pch=20, col=\"forestgreen\") # Try different colors?\ndev.off() # Close the file using the dev.off function\n\nquartz_off_screen \n                2 \n\nx=seq(1,10) # Same as x=c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=seq(-pi,pi,length=50)\ny=x"
  }
]